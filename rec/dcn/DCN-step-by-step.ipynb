{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文链接：https://arxiv.org/abs/1708.05123\n",
    "\n",
    "\n",
    "### 交叉网络（Cross Network）\n",
    "- 交叉网络用于捕捉特征的低阶交互作用。\n",
    "- 通过多个交叉层（Cross Layer）逐层递归计算，每一层的输出作为下一层的输入。\n",
    "- 每一层的计算方式为：$$ x_{i + 1} = x_0 x_i^T W_c + b_c + x_i $$\n",
    "  - 其中，$ x_0 $ 是初始输入特征向量，$ W_c $ 是权重矩阵，$ b_c $ 是偏置。\n",
    "- 交叉网络的输出为 $ x_{l} $。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train: (10000, 39)\n",
      "Shape of y_train: (10000,)\n",
      "Shape of X_test: (2000, 39)\n",
      "Shape of ids_test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 列出需要忽略的列，这些列在后续的建模过程中不会使用\n",
    "IGNORE_COLS = [\n",
    "    \"id\", \"target\",\n",
    "    \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\",\n",
    "    \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\",\n",
    "    \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\",\n",
    "    \"ps_calc_13\", \"ps_calc_14\",\n",
    "    \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\",\n",
    "    \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    # # binary\n",
    "    # \"ps_ind_06_bin\", \"ps_ind_07_bin\", \"ps_ind_08_bin\",\n",
    "    # \"ps_ind_09_bin\", \"ps_ind_10_bin\", \"ps_ind_11_bin\",\n",
    "    # \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_ind_16_bin\",\n",
    "    # \"ps_ind_17_bin\", \"ps_ind_18_bin\",\n",
    "    # \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\",\n",
    "    # \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\",\n",
    "    # numeric\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "    \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\",\n",
    "\n",
    "    # feature engineering\n",
    "    \"missing_feat\", \"ps_car_13_x_ps_reg_03\",\n",
    "]\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    从远程URL加载训练和测试数据集，并进行预处理。\n",
    "    \n",
    "    Returns:\n",
    "        dfTrain (pd.DataFrame): 预处理后的训练数据集。\n",
    "        dfTest (pd.DataFrame): 预处理后的测试数据集。\n",
    "        X_train (np.ndarray): 训练特征数组。\n",
    "        y_train (np.ndarray): 训练目标数组。\n",
    "        X_test (np.ndarray): 测试特征数组。\n",
    "        ids_test (np.ndarray): 测试集中的ID数组。\n",
    "    \"\"\"\n",
    "    \n",
    "    dfTrain = pd.read_csv(\"https://testonly-2023.oss-cn-hangzhou.aliyuncs.com/data/common/train.csv\")\n",
    "    dfTest = pd.read_csv(\"https://testonly-2023.oss-cn-hangzhou.aliyuncs.com/data/common/test.csv\")\n",
    "    \n",
    "    def preprocess(df):\n",
    "        \"\"\"\n",
    "        对数据集进行预处理，包括添加缺失值特征和计算新的特征列。\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): 输入的数据集。\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: 预处理后的数据集。\n",
    "        \"\"\"\n",
    "        # 过滤掉 'id' 和 'target' 列，其余所有列都进行预处理\n",
    "        cols = [c for c in df.columns if c not in [\"id\", \"target\"]]\n",
    "        \n",
    "        # 计算每行中缺失值 (-1) 的数量，作为一个新的特征列 'missing_feat'\n",
    "        df[\"missing_feat\"] = np.sum((df[cols] == -1).values, axis=1)\n",
    "        \n",
    "        # 将 'ps_car_13' 列和 'ps_reg_03' 列相乘，生成新特征列 'ps_car_13_x_ps_reg_03'\n",
    "        df[\"ps_car_13_x_ps_reg_03\"] = df[\"ps_car_13\"] * df[\"ps_reg_03\"]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # 对训练和测试数据集进行预处理\n",
    "    dfTrain = preprocess(dfTrain)\n",
    "    dfTest = preprocess(dfTest)\n",
    "    \n",
    "    # 过滤掉 'id' 和 'target' 列，并排除 IGNORE_COLS 中列出的列\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"id\", \"target\"]]\n",
    "    cols = [c for c in cols if (not c in IGNORE_COLS)]\n",
    "    \n",
    "    # 提取训练特征、目标和测试特征、ID\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"target\"].values\n",
    "    X_test = dfTest[cols].values\n",
    "    ids_test = dfTest[\"id\"].values\n",
    "    \n",
    "    return dfTrain, dfTest, X_train, y_train, X_test, ids_test\n",
    "\n",
    "# 加载并预处理数据\n",
    "dfTrain, dfTest, X_train, y_train, X_test, ids_test = load_data()\n",
    "\n",
    "# 打印数据类型和一些基本信息\n",
    "print(\"\\nShape of X_train:\", X_train.shape)  # 打印训练特征数组的形状\n",
    "print(\"Shape of y_train:\", y_train.shape)  # 打印训练目标数组的形状\n",
    "print(\"Shape of X_test:\", X_test.shape)  # 打印测试特征数组的形状\n",
    "print(\"Shape of ids_test:\", ids_test.shape)  # 打印测试集ID数组的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_feature_dictionary(df, ignore_cols, numeric_cols):\n",
    "    \"\"\"\n",
    "    生成特征字典并计算特征维度。\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 输入的数据框。\n",
    "        ignore_cols (list): 需要忽略的列列表。\n",
    "        numeric_cols (list): 数值列列表，这些列也会被忽略。\n",
    "    \n",
    "    Returns:\n",
    "        dict: 特征字典，其中每列的唯一值映射到一个唯一索引。\n",
    "        int: 特征的维度，即唯一特征值的总数。\n",
    "    \"\"\"\n",
    "    # 初始化特征计数器\n",
    "    feature_counter = 0\n",
    "    \n",
    "    # 存储每列的特征映射\n",
    "    feature_dictionary = {}\n",
    "    \n",
    "    # 遍历 DataFrame 中的每一列\n",
    "    for column in df.columns:\n",
    "        # 忽略指定的列和数值列\n",
    "        if column in ignore_cols or column in numeric_cols:\n",
    "            continue\n",
    "        \n",
    "        # 获取列中唯一值的集合\n",
    "        unique_values = df[column].unique()\n",
    "        \n",
    "        # 创建特征字典，其中键为唯一值，值为从 feature_counter 开始的递增索引\n",
    "        feature_dictionary[column] = {val: idx for idx, val in enumerate(unique_values, start=feature_counter)}\n",
    "        \n",
    "        # 更新特征计数器\n",
    "        feature_counter += len(unique_values)\n",
    "    \n",
    "    # 设置特征维度\n",
    "    feature_dimension = feature_counter\n",
    "    \n",
    "    return feature_dictionary, feature_dimension\n",
    "\n",
    "combined_df = pd.concat([dfTrain, dfTest])\n",
    "\n",
    "feature_dict, feature_dim = generate_feature_dictionary(combined_df, IGNORE_COLS, NUMERIC_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Category Feature Indices (cate_Xi): (10000, 30)\n",
      "Shape of Category Feature Values (cate_Xv): (10000, 30)\n",
      "Size of Numeric Feature Values (numeric_Xv): (10000, 9)\n",
      "Size of Target Labels (y): (10000,)\n",
      "[  0   8  13  25  28  36  38  40  42  44  46  48  50  52  56  70  72  74\n",
      "  76  89  91  94 104 107 125 128 130 136 139 243]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def parse(df, ignore_cols, numeric_cols, feat_dict=None, has_label=False):\n",
    "    \"\"\"\n",
    "    解析输入的 DataFrame。\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 输入的数据框。\n",
    "        ignore_cols (list): 需要忽略的列名列表。\n",
    "        numeric_cols (list): 数值型特征列名列表。\n",
    "        feat_dict (dict): 分类特征映射字典（默认为 None）。\n",
    "        has_label (bool): 表示是否包含目标列 'target'。\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 包含解析后的特征索引数组、特征值数组，以及数值型特征数组和标签或 ID。\n",
    "    \"\"\"\n",
    "    assert feat_dict is not None, \"feat_dict must be provided\"\n",
    "\n",
    "    # 创建一个 DataFrame 的副本以避免修改原始数据\n",
    "    dfi = df.copy()\n",
    "\n",
    "    if has_label:\n",
    "        # 提取目标列 'target' 并移除 'id' 和 'target' 列\n",
    "        y = dfi[\"target\"].values\n",
    "        dfi.drop([\"id\", \"target\"], axis=1, inplace=True)\n",
    "    else:\n",
    "        # 提取 'id' 列并移除 'id' 列\n",
    "        ids = dfi[\"id\"].values\n",
    "        dfi.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "    # 获取数值型特征的数据并转换为 numpy.ndarray\n",
    "    numeric_Xv = dfi[numeric_cols].values\n",
    "    dfi.drop(numeric_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # 创建 dfv 数据框，用于存储特征值\n",
    "    dfv = dfi.copy()\n",
    "\n",
    "    # 标识分类特征的索引（one-hot编码方式）\n",
    "    for col in dfi.columns:\n",
    "        if col in ignore_cols:\n",
    "            dfi.drop(col, axis=1, inplace=True)\n",
    "            dfv.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            dfi[col] = dfi[col].map(feat_dict[col])\n",
    "            dfv[col] = 1.0\n",
    "\n",
    "    # 将特征索引转换为 numpy.ndarray\n",
    "    cate_Xi = dfi.values\n",
    "    # 将特征值转换为 numpy.ndarray\n",
    "    cate_Xv = dfv.values\n",
    "\n",
    "    if has_label:\n",
    "        return cate_Xi, cate_Xv, numeric_Xv, y\n",
    "    else:\n",
    "        return cate_Xi, cate_Xv, numeric_Xv, ids\n",
    "\n",
    "\n",
    "cate_Xi_train, cate_Xv_train, numeric_Xv_train, y_train = \\\n",
    "    parse(dfTrain, IGNORE_COLS, NUMERIC_COLS, feature_dict, has_label=True)\n",
    "cate_Xi_test, cate_Xv_test, numeric_Xv_test,ids_test = \\\n",
    "    parse(dfTest, IGNORE_COLS, NUMERIC_COLS, feature_dict, has_label=False)\n",
    "\n",
    "print(\"Shape of Category Feature Indices (cate_Xi):\", cate_Xi_train.shape)\n",
    "print(\"Shape of Category Feature Values (cate_Xv):\", cate_Xv_train.shape)\n",
    "print(\"Size of Numeric Feature Values (numeric_Xv):\", numeric_Xv_train.shape)\n",
    "print(\"Size of Target Labels (y):\", y_train.shape)\n",
    "\n",
    "print(cate_Xi_train[0])\n",
    "print(cate_Xv_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 249, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def initialize_graph(cate_feature_dim: int, \n",
    "                     cate_field_num: int, \n",
    "                     embedding_size: int, \n",
    "                     numeric_field_num: int,\n",
    "                     cross_layer_num: int):\n",
    "    \"\"\"\n",
    "    初始化TensorFlow计算图并返回会话和必要的张量。\n",
    "    \n",
    "    Args:\n",
    "        cate_feature_dim (int): 类别特征的。\n",
    "        cate_field_num (int): 类别字段的数量。\n",
    "        embedding_size (int): 嵌入向量的大小。\n",
    "    \n",
    "    Returns:\n",
    "        session: 初始化的TensorFlow会话。\n",
    "        x0: 拼接后的输入张量。\n",
    "        feat_index: 类别特征索引的占位符。\n",
    "        feat_value: 类别特征值的占位符。\n",
    "        numeric_value: 数值特征值的占位符。\n",
    "        label: 标签的占位符。\n",
    "    \"\"\"\n",
    "    random_seed = 2024\n",
    "    glorot = 0.1 # glorot 初始化参数\n",
    "    total_size = cate_field_num * embedding_size + numeric_field_num\n",
    "    graph = tf.Graph()\n",
    "    x0 = None\n",
    "    session = None\n",
    "\n",
    "    with graph.as_default():\n",
    "        # 设置随机种子\n",
    "        tf.set_random_seed(random_seed)\n",
    "\n",
    "        # 定义占位符\n",
    "        feat_index = tf.placeholder(tf.int32, shape=[None, None], name='feat_index')\n",
    "        feat_value = tf.placeholder(tf.float32, shape=[None, None], name='feat_value')\n",
    "        numeric_value = tf.placeholder(tf.float32, [None, None], name='num_value')\n",
    "        label = tf.placeholder(tf.float32, shape=[None, 1], name='label')\n",
    "        \n",
    "        \n",
    "        # 初始化权重\n",
    "        weights = dict()\n",
    "        \n",
    "        weights['feature_embeddings'] = tf.Variable(\n",
    "            tf.random_normal([cate_feature_dim, embedding_size], 0.0, 0.01),\n",
    "            name='feature_embeddings'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        for l in range(cross_layer_num):\n",
    "            layer_weight_name = f\"cross_layer_{l}\"\n",
    "            layer_bias_name = f\"cross_bias_{l}\"\n",
    "\n",
    "            weights[layer_weight_name] = tf.Variable(\n",
    "                np.random.normal(loc=0, scale=glorot, size=(total_size, 1)),\n",
    "                dtype=np.float32, name=layer_weight_name)\n",
    "\n",
    "            weights[layer_bias_name] = tf.Variable(\n",
    "                np.random.normal(loc=0, scale=glorot, size=(total_size, 1)),\n",
    "                dtype=np.float32, name=layer_bias_name)\n",
    "        \n",
    "\n",
    "        # 查找嵌入向量\n",
    "        embeddings = tf.nn.embedding_lookup(weights['feature_embeddings'], feat_index)\n",
    "\n",
    "        # 重塑特征值张量以匹配嵌入维度\n",
    "        feat_value_reshape = tf.reshape(feat_value, shape=[-1, cate_field_num, 1])\n",
    "        \n",
    "        \n",
    "        # 按元素相乘以调整嵌入\n",
    "        embeddings = tf.multiply(embeddings, feat_value_reshape)\n",
    "        \n",
    "        # 重塑嵌入张量为平坦的维度\n",
    "        embeddings_reshape = tf.reshape(embeddings, shape=[-1, cate_field_num * embedding_size])  \n",
    "        \n",
    "        # 拼接数值特征和类别特征\n",
    "        x0 = tf.concat([numeric_value, embeddings_reshape], axis=1)\n",
    "        \n",
    "        x0_reshape = tf.reshape(x0, (-1, total_size, 1))\n",
    "        \n",
    "        # 初始输入\n",
    "        x_l = x0_reshape\n",
    "\n",
    "        for l in range(cross_layer_num):\n",
    "            # 执行矩阵乘法和交叉乘法\n",
    "            weight = weights[f\"cross_layer_{l}\"]\n",
    "            cross_mul = tf.tensordot(tf.matmul(x0_reshape, x_l, transpose_b=True), weight, axes=1)\n",
    "\n",
    "            # 加上偏置和当前的 x_l\n",
    "            bias_weight = weights[f\"cross_bias_{l}\"]\n",
    "            x_l = cross_mul + bias_weight + x_l\n",
    "\n",
    "        \n",
    "        # 初始化所有变量\n",
    "        initializer = tf.global_variables_initializer()\n",
    "        \n",
    "        # 创建会话并初始化变量\n",
    "        session = tf.Session()\n",
    "        session.run(initializer)\n",
    "\n",
    "    return session, x_l, feat_index, feat_value, numeric_value, label\n",
    "           \n",
    "\n",
    "cate_feature_dim = feature_dim\n",
    "cate_field_num = cate_Xi_train.shape[1]\n",
    "numeric_field_num = numeric_Xv_train.shape[1]\n",
    "embedding_size = 8\n",
    "cross_layer_num = 3\n",
    "\n",
    "session, xl, feat_index, feat_value, numeric_value, label = \\\n",
    "    initialize_graph(cate_feature_dim = cate_feature_dim, \n",
    "                     cate_field_num = cate_field_num, \n",
    "                     embedding_size = embedding_size, \n",
    "                     numeric_field_num = numeric_field_num,\n",
    "                     cross_layer_num = cross_layer_num)\n",
    "\n",
    "feed_dict = {\n",
    "    feat_index: cate_Xi_train,\n",
    "    feat_value: cate_Xv_train,\n",
    "    numeric_value: numeric_Xv_train,\n",
    "    label: y_train.reshape(-1, 1)\n",
    "}\n",
    "\n",
    "xl_result = session.run(xl, feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "print(xl_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
