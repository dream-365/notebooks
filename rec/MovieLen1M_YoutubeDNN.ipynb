{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtox72csOQUN"
   },
   "source": [
    "# 资料参考\n",
    "- [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9UxNHuPMuW2"
   },
   "source": [
    "# 导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C_ZR6gzp1E2N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, get_feature_names\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss, NegativeSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQq6O9XAMzPF"
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcO29zFb21Od",
    "outputId": "bfeed1ac-99f2-425f-dda6-10b83be721fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>watch_movie_seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2456</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>974181965</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1598</td>\n",
       "      <td>[2484, 2890, 1026, 1575, 709, 2558, 145, 1, 96...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4964</td>\n",
       "      <td>1154</td>\n",
       "      <td>4</td>\n",
       "      <td>962620051</td>\n",
       "      <td>Miller's Crossing (1990)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3058</td>\n",
       "      <td>[2163, 859, 2587, 1839, 2593, 690, 1179, 514, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4747</td>\n",
       "      <td>1030</td>\n",
       "      <td>3</td>\n",
       "      <td>963241794</td>\n",
       "      <td>Top Gun (1986)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>958</td>\n",
       "      <td>[1108, 1179, 2970, 2558, 254, 2014, 2427, 1121...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5824</td>\n",
       "      <td>2327</td>\n",
       "      <td>1</td>\n",
       "      <td>957969367</td>\n",
       "      <td>Airport 1975 (1974)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>692</td>\n",
       "      <td>[640, 854, 2163, 1108, 1196, 581, 859, 582, 97...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058</td>\n",
       "      <td>2331</td>\n",
       "      <td>2</td>\n",
       "      <td>974957947</td>\n",
       "      <td>Alligator (1980)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3303</td>\n",
       "      <td>[1105, 1108, 859, 2587, 1179, 1026, 2489, 254,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp                       title  genres  \\\n",
       "0     2456        50       5  974181965  Usual Suspects, The (1995)       6   \n",
       "1     4964      1154       4  962620051    Miller's Crossing (1990)       8   \n",
       "2     4747      1030       3  963241794              Top Gun (1986)       1   \n",
       "3     5824      2327       1  957969367         Airport 1975 (1974)       8   \n",
       "4     1058      2331       2  974957947            Alligator (1980)       1   \n",
       "\n",
       "   gender  age  occupation   zip  \\\n",
       "0       2    3           6  1598   \n",
       "1       2    4           1  3058   \n",
       "2       2    2           5   958   \n",
       "3       2    2          13   692   \n",
       "4       2    3           2  3303   \n",
       "\n",
       "                                     watch_movie_seq  label  \n",
       "0  [2484, 2890, 1026, 1575, 709, 2558, 145, 1, 96...      1  \n",
       "1  [2163, 859, 2587, 1839, 2593, 690, 1179, 514, ...      1  \n",
       "2  [1108, 1179, 2970, 2558, 254, 2014, 2427, 1121...      1  \n",
       "3  [640, 854, 2163, 1108, 1196, 581, 859, 582, 97...      1  \n",
       "4  [1105, 1108, 859, 2587, 1179, 1026, 2489, 254,...      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_df = pd.read_parquet('ml1M-train.parquet', engine='pyarrow')\n",
    "test_df = pd.read_parquet('ml1M-test.parquet', engine='pyarrow')\n",
    "\n",
    "train_df['label'] = 1\n",
    "test_df['label'] = 1\n",
    "\n",
    "with open('ml1M_feature_max_idx.json', 'r') as json_file:\n",
    "    feature_max_idx = json.load(json_file)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input(data, seq_max_len = 50):\n",
    "    fixlen_feature_columns = ['user_id', 'movie_id', 'genres', \n",
    "                               'rating','gender', 'age', \n",
    "                              'occupation', 'zip']\n",
    "\n",
    "    varlen_feature_columns = ['watch_movie_seq', ]\n",
    "\n",
    "    _dict = data[fixlen_feature_columns].to_dict(orient='list')\n",
    "\n",
    "    for feature in fixlen_feature_columns:\n",
    "        _dict[feature] = np.array(_dict[feature])\n",
    "\n",
    "    for feature in varlen_feature_columns:\n",
    "        _dict[feature] = \\\n",
    "            pad_sequences(data[feature].values, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
    "        \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练数据\n",
    "train_model_input = get_model_input(train_df)\n",
    "train_label = np.array(train_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0yCWxQxM3se"
   },
   "source": [
    "# 构建特征列，训练模型，导出embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMOvk_de2ML3",
    "outputId": "962afe1c-d387-4345-861f-e9b974a0b495"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "N_EPOCHS = 20\n",
    "SEQ_LEN = 50\n",
    "embedding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class FeatureConfig:\n",
    "    def __init__(self, feature_max_idx, embedding_dim=32, seq_len=50):\n",
    "        self.feature_max_idx = feature_max_idx\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def get_user_feature_columns(self):\n",
    "        \"\"\"生成用户特征列配置\"\"\"\n",
    "        return [\n",
    "            SparseFeat('user_id', self.feature_max_idx['user_id'], 16),\n",
    "            SparseFeat(\"gender\", self.feature_max_idx['gender'], 16),\n",
    "            SparseFeat(\"age\", self.feature_max_idx['age'], 16),\n",
    "            SparseFeat(\"occupation\", self.feature_max_idx['occupation'], 16),\n",
    "            SparseFeat(\"zip\", self.feature_max_idx['zip'], 16),\n",
    "            VarLenSparseFeat(SparseFeat('watch_movie_seq', self.feature_max_idx['movie_id'], self.embedding_dim,\n",
    "                                        embedding_name=\"movie_id\"), self.seq_len, 'mean'),\n",
    "        ]\n",
    "\n",
    "    def get_item_feature_columns(self):\n",
    "        \"\"\"生成物品特征列配置\"\"\"\n",
    "        return [SparseFeat('movie_id', self.feature_max_idx['movie_id'], self.embedding_dim)]\n",
    "\n",
    "class NegativeSamplerConfig:\n",
    "    def __init__(self, train_model_input, item_feature_columns):\n",
    "        self.train_counter = Counter(train_model_input['movie_id'])\n",
    "        self.item_count = [self.train_counter.get(i, 0) for i in range(item_feature_columns[0].vocabulary_size)]\n",
    "\n",
    "    def get_sampler_config(self, num_sampled=255):\n",
    "        \"\"\"生成负采样器配置\"\"\"\n",
    "        return NegativeSampler('frequency', num_sampled=num_sampled, item_name=\"movie_id\", item_count=self.item_count)\n",
    "    \n",
    "# 创建 FeatureConfig 实例\n",
    "feature_config = FeatureConfig(feature_max_idx, embedding_dim, SEQ_LEN)\n",
    "user_feature_columns = feature_config.get_user_feature_columns()\n",
    "item_feature_columns = feature_config.get_item_feature_columns()\n",
    "\n",
    "# 创建 NegativeSamplerConfig 实例\n",
    "negative_sampler_config = NegativeSamplerConfig(train_model_input, item_feature_columns)\n",
    "sampler_config = negative_sampler_config.get_sampler_config(num_sampled=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Train on 900189 samples\n",
      "Epoch 1/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 6.2956\n",
      "Epoch 2/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 5.2375\n",
      "Epoch 3/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.9377\n",
      "Epoch 4/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.7678\n",
      "Epoch 5/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.6458\n",
      "Epoch 6/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.5492\n",
      "Epoch 7/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.4786\n",
      "Epoch 8/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.4171\n",
      "Epoch 9/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.3649\n",
      "Epoch 10/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.3211\n",
      "Epoch 11/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.2822\n",
      "Epoch 12/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.2462\n",
      "Epoch 13/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.2200\n",
      "Epoch 14/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.1913\n",
      "Epoch 15/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.1635\n",
      "Epoch 16/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.1434\n",
      "Epoch 17/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.1246\n",
      "Epoch 18/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.1074\n",
      "Epoch 19/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.0912\n",
      "Epoch 20/20\n",
      "900189/900189 [==============================] - 10s 11us/sample - loss: 4.0773\n"
     ]
    }
   ],
   "source": [
    "# 3.Define Model and train\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.__version__ >= '2.0.0':\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "else:\n",
    "    K.set_learning_phase(True)\n",
    "\n",
    "model = YoutubeDNN(user_feature_columns, item_feature_columns, user_dnn_hidden_units=(128,64, embedding_dim), sampler_config=sampler_config)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=sampledsoftmaxloss)\n",
    "\n",
    "history = model.fit(train_model_input, train_label,  # train_label,\n",
    "                    batch_size=BATCH_SIZE, epochs=N_EPOCHS, verbose=1, validation_split=0.0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练数据\n",
    "test_model_input = get_model_input(test_df)\n",
    "test_label = np.array(train_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 垂直训练集和测试集，取movie_id的唯一值\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "movide_id_list = all_data['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100020, 32)\n",
      "(3706, 32)\n"
     ]
    }
   ],
   "source": [
    "# 4. Generate user features for testing and full item features for retrieval\n",
    "test_user_model_input = test_model_input\n",
    "all_item_model_input = {\"movie_id\": movide_id_list,}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "# user_embs = user_embs[:, i, :]  # i in [0,k_max) if MIND\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_G3KWslKmJo"
   },
   "source": [
    "# 使用faiss进行ANN查找并评估结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TY1l27iJU8U",
    "outputId": "5a8ccdd3-af70-4c48-b859-84c4befddfdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100020it [00:17, 5843.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall 0.12580483903219356\n",
      "hit rate 0.12580483903219356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_true_label = {row.user_id:[row.movie_id] for row in test_df.itertuples(index=False)}\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from deepmatch.utils import recall_N\n",
    "\n",
    "TOP_N = 100\n",
    "\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "# faiss.normalize_L2(item_embs)\n",
    "index.add(item_embs)\n",
    "# faiss.normalize_L2(user_embs)\n",
    "D, I = index.search(np.ascontiguousarray(user_embs), TOP_N)\n",
    "s = []\n",
    "hit = 0\n",
    "for i, uid in tqdm(enumerate(test_user_model_input['user_id'])):\n",
    "    try:\n",
    "        pred_movie_ids = [movide_id_list[x] for x in I[i]]\n",
    "        filter_item = None\n",
    "        recall_score = recall_N(test_true_label[uid], pred_movie_ids, N=TOP_N)\n",
    "        s.append(recall_score)\n",
    "        if test_true_label[uid] in pred_movie_ids:\n",
    "            hit += 1\n",
    "    except:\n",
    "        print(i)\n",
    "print(\"\")\n",
    "print(\"recall\", np.mean(s))\n",
    "print(\"hit rate\", hit / len(test_user_model_input['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "colab_MovieLen1M_YoutubeDNN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
